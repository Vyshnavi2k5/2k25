{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVaf0SrmdRrUAUOADu+SlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyshnavi2k5/2k25/blob/main/Untitled31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG4I-1iBu6dr",
        "outputId": "358c40a9-b8c8-4ecb-c3f0-1329e5f80f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (55500, 15)\n",
            "Columns: ['Name', 'Age', 'Gender', 'Blood Type', 'Medical Condition', 'Date of Admission', 'Doctor', 'Hospital', 'Insurance Provider', 'Billing Amount', 'Room Number', 'Admission Type', 'Discharge Date', 'Medication', 'Test Results']\n"
          ]
        }
      ],
      "source": [
        "# ================= ENSEMBLE LEARNING FOR HEALTHCARE DATA =================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    ExtraTreesClassifier,\n",
        "    VotingClassifier,\n",
        "    StackingClassifier\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ========== LOAD DATA ==========\n",
        "zip_path = \"/content/Healthcare dataset.zip\"   # Update path if needed\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    file_name = z.namelist()[0]  # assume first CSV inside zip\n",
        "    df = pd.read_csv(z.open(file_name))\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# ========== SELECT TARGET ==========\n",
        "# Example: predict \"Medical Condition\"\n",
        "target = \"Medical Condition\"\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "# ========== TRAIN/TEST SPLIT ==========\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ========== PREPROCESSING ==========\n",
        "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ========== BASE MODELS ==========\n",
        "log_reg = LogisticRegression(max_iter=200)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "et = ExtraTreesClassifier(random_state=42)\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=42)\n",
        "\n",
        "# ========== ENSEMBLE TECHNIQUES ==========\n",
        "ensembles = {\n",
        "    \"Voting_Hard\": VotingClassifier(\n",
        "        estimators=[(\"lr\", log_reg), (\"rf\", rf), (\"xgb\", xgb)], voting=\"hard\"\n",
        "    ),\n",
        "    \"Voting_Soft\": VotingClassifier(\n",
        "        estimators=[(\"lr\", log_reg), (\"rf\", rf), (\"xgb\", xgb)], voting=\"soft\"\n",
        "    ),\n",
        "    \"Bagging_RF\": rf,\n",
        "    \"Bagging_ET\": et,\n",
        "    \"Boosting_GB\": gb,\n",
        "    \"Boosting_Ada\": ada,\n",
        "    \"Boosting_XGB\": xgb,\n",
        "    \"Stacking\": StackingClassifier(\n",
        "        estimators=[(\"rf\", rf), (\"gb\", gb), (\"xgb\", xgb)],\n",
        "        final_estimator=LogisticRegression(),\n",
        "        passthrough=True,\n",
        "    ),\n",
        "}\n",
        "\n",
        "# ========== TRAIN & EVALUATE ==========\n",
        "for name, model in ensembles.items():\n",
        "    clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred)[:600])  # shortened output\n"
      ]
    }
  ]
}